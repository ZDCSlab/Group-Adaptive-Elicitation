{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4731e2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(caseid_lst) 6175\n",
      "Year=20 - TopK=1  Average overall_match_rate_mean: 0.6462068548903752\n",
      "Year=20 - TopK=3  Average overall_match_rate_mean: 0.6427965020088824\n",
      "Year=20 - TopK=5  Average overall_match_rate_mean: 0.6430480309857971\n",
      "Year=20 - TopK=10  Average overall_match_rate_mean: 0.6396983832200004\n",
      "Year=20 - TopK=15  Average overall_match_rate_mean: 0.6391148873997874\n",
      "Year=20 - TopK=20  Average overall_match_rate_mean: 0.6375436392419819\n",
      "Year=20 - TopK=25  Average overall_match_rate_mean: 0.6365780819859783\n",
      "Year=20 - TopK=30  Average overall_match_rate_mean: 0.636317245484725\n",
      "len(caseid_lst) 6175\n",
      "Year=22 - TopK=1  Average overall_match_rate_mean: 0.6334547078716286\n",
      "Year=22 - TopK=3  Average overall_match_rate_mean: 0.6345493848018263\n",
      "Year=22 - TopK=5  Average overall_match_rate_mean: 0.6370145489469016\n",
      "Year=22 - TopK=10  Average overall_match_rate_mean: 0.6365390754861467\n",
      "Year=22 - TopK=15  Average overall_match_rate_mean: 0.6359297905504931\n",
      "Year=22 - TopK=20  Average overall_match_rate_mean: 0.6351491986233303\n",
      "Year=22 - TopK=25  Average overall_match_rate_mean: 0.6342136801000872\n",
      "Year=22 - TopK=30  Average overall_match_rate_mean: 0.6342433106697728\n",
      "len(caseid_lst) 6175\n",
      "Year=24 - TopK=1  Average overall_match_rate_mean: 0.6411943579362608\n",
      "Year=24 - TopK=3  Average overall_match_rate_mean: 0.6387701007943923\n",
      "Year=24 - TopK=5  Average overall_match_rate_mean: 0.6398309937925323\n",
      "Year=24 - TopK=10  Average overall_match_rate_mean: 0.6375804690305196\n",
      "Year=24 - TopK=15  Average overall_match_rate_mean: 0.6377900894689357\n",
      "Year=24 - TopK=20  Average overall_match_rate_mean: 0.6380645131974\n",
      "Year=24 - TopK=25  Average overall_match_rate_mean: 0.6381465121742855\n",
      "Year=24 - TopK=30  Average overall_match_rate_mean: 0.6375762534377867\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Iterable, Optional, Union\n",
    "\n",
    "\n",
    "def load_jsonl_as_dict_of_dict(path, key=None):\n",
    "    data = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            data[obj[key]] = obj  \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def neighbor_match_rates(\n",
    "    df_survey: pd.DataFrame,\n",
    "    neighbors_info: dict,\n",
    "    *,\n",
    "    id_col: str = \"caseid\",\n",
    "    question_cols=None,\n",
    "    top_k: int | None = None,\n",
    "):\n",
    "    if id_col not in df_survey.columns:\n",
    "        raise ValueError(f\"`{id_col}` not found in survey data.\")\n",
    "    if question_cols is None:\n",
    "        question_cols = [c for c in df_survey.columns if c != id_col]\n",
    "\n",
    "    # --- clean survey data ---\n",
    "    df = df_survey.copy()\n",
    "    df = df.replace(-1, np.nan)\n",
    "    df[id_col] = df[id_col].astype(str)\n",
    "\n",
    "    # map caseid -> row index\n",
    "    id_to_idx = pd.Series(df.index.values, index=df[id_col]).to_dict()\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        cid = row[id_col]\n",
    "        neighbors = neighbors_info.get(cid, [])\n",
    "        if isinstance(neighbors, dict) and \"neighbors\" in neighbors:\n",
    "            neighbors = neighbors[\"neighbors\"]\n",
    "\n",
    "        neighbors = [str(n) for n in neighbors if str(n) in id_to_idx and str(n) != cid]\n",
    "        if top_k:\n",
    "            neighbors = neighbors[:top_k]\n",
    "\n",
    "        d = {id_col: cid}\n",
    "        rates = []\n",
    "\n",
    "        if not neighbors:\n",
    "            for q in question_cols:\n",
    "                d[f\"{q}__match_rate\"] = np.nan\n",
    "            d[\"overall_match_rate_mean\"] = np.nan\n",
    "            results.append(d)\n",
    "            continue\n",
    "\n",
    "        nb_df = df.loc[[id_to_idx[n] for n in neighbors], question_cols]\n",
    "        for q in question_cols:\n",
    "            my_ans = row[q]\n",
    "            if pd.isna(my_ans):\n",
    "                d[f\"{q}__match_rate\"] = np.nan\n",
    "            else:\n",
    "                valid_nb = nb_df[q].dropna()\n",
    "                d[f\"{q}__match_rate\"] = (valid_nb == my_ans).mean() if not valid_nb.empty else np.nan\n",
    "                if not pd.isna(d[f\"{q}__match_rate\"]):\n",
    "                    rates.append(d[f\"{q}__match_rate\"])\n",
    "\n",
    "        d[\"overall_match_rate_mean\"] = np.nanmean(rates) if rates else np.nan\n",
    "        results.append(d)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "for year in ['20', '22', '24']:\n",
    "    jsonl_file = f\"/home/ruomeng/gae/dataset/ces/raw/{year}/neighbors_top30_semantic_{year}.jsonl\"  \n",
    "    neighbors_info = load_jsonl_as_dict_of_dict(jsonl_file, key='caseid')\n",
    "    caseid_lst = list(neighbors_info.keys())\n",
    "    print('len(caseid_lst)', len(caseid_lst))\n",
    "    # print(neighbors_info['1249937987'])\n",
    "    df_survey = pd.read_csv(f\"/home/ruomeng/gae/dataset/ces/raw/{year}/question_{year}.csv\")\n",
    "\n",
    "    # Example usage:\n",
    "    for top_k in [1, 3, 5, 10, 15, 20, 25, 30]:\n",
    "        sim_df = neighbor_match_rates(df_survey, neighbors_info, id_col=\"caseid\", top_k=top_k)\n",
    "        avg_rate = sim_df[\"overall_match_rate_mean\"].mean(skipna=True)\n",
    "        print('Year=%s - TopK=%s '%(year, top_k), \"Average overall_match_rate_mean:\", avg_rate)\n",
    "        sim_df.to_csv('./analysis/analysis_neighbor_top%s_%s.csv'%(top_k, year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4fab04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(caseid_lst) 6175\n",
      "Year=20 - TopK=30  Average overall_mode_match_mean: 0.7118619265065904\n",
      "len(caseid_lst) 6175\n",
      "Year=22 - TopK=30  Average overall_mode_match_mean: 0.7112445333675073\n",
      "len(caseid_lst) 6175\n",
      "Year=24 - TopK=30  Average overall_mode_match_mean: 0.7149492131970796\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "def neighbor_mode_match(\n",
    "    df_survey: pd.DataFrame,\n",
    "    neighbors_info: Dict[str, List[str] | Dict],\n",
    "    *,\n",
    "    id_col: str = \"caseid\",\n",
    "    question_cols: Optional[List[str]] = None,\n",
    "    top_k: Optional[int] = None,\n",
    "    tie_policy: str = \"strict\",  # \"strict\" | \"lenient\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each respondent and question, compare the respondent's answer to the mode\n",
    "    of their neighbors' answers.\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "      - <q>__mode_match: True/False/NaN  (NaN when no neighbors or no unique mode under 'strict')\n",
    "      - overall_mode_match_mean: mean of <q>__mode_match over questions (ignoring NaN)\n",
    "\n",
    "    Args:\n",
    "      df_survey:       rows = respondents, columns include id_col and question columns\n",
    "      neighbors_info:  mapping id -> list of neighbor ids, or {\"neighbors\": [...]}\n",
    "      id_col:          id column in df_survey\n",
    "      question_cols:   which columns to evaluate; default = all non-id columns\n",
    "      top_k:           if set, only use the first top_k neighbors\n",
    "      tie_policy:      \"strict\": require unique mode; ties -> NaN\n",
    "                       \"lenient\": ties -> match if own answer is among tied top answers\n",
    "    \"\"\"\n",
    "    if id_col not in df_survey.columns:\n",
    "        raise ValueError(f\"`{id_col}` not found in survey data.\")\n",
    "    if question_cols is None:\n",
    "        question_cols = [c for c in df_survey.columns if c != id_col]\n",
    "    if tie_policy not in (\"strict\", \"lenient\"):\n",
    "        raise ValueError(\"tie_policy must be 'strict' or 'lenient'\")\n",
    "\n",
    "    # --- clean survey data ---\n",
    "    df = df_survey.copy()\n",
    "    df = df.replace(-1, np.nan)   # treat -1 as missing if that's your convention\n",
    "    df[id_col] = df[id_col].astype(str)\n",
    "\n",
    "    # map caseid -> row index\n",
    "    id_to_idx = pd.Series(df.index.values, index=df[id_col]).to_dict()\n",
    "\n",
    "    out_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        cid = row[id_col]\n",
    "        neighbors = neighbors_info.get(cid, [])\n",
    "        if isinstance(neighbors, dict) and \"neighbors\" in neighbors:\n",
    "            neighbors = neighbors[\"neighbors\"]\n",
    "\n",
    "        # normalize neighbor ids\n",
    "        neighbors = [str(n) for n in neighbors if str(n) in id_to_idx and str(n) != cid]\n",
    "        if top_k:\n",
    "            neighbors = neighbors[:top_k]\n",
    "\n",
    "        d = {id_col: cid}\n",
    "        per_q_matches = []\n",
    "\n",
    "        if not neighbors:\n",
    "            # no neighbors → NaN for all questions\n",
    "            for q in question_cols:\n",
    "                d[f\"{q}__mode_match\"] = np.nan\n",
    "            d[\"overall_mode_match_mean\"] = np.nan\n",
    "            out_rows.append(d)\n",
    "            continue\n",
    "\n",
    "        nb_df = df.loc[[id_to_idx[n] for n in neighbors], question_cols]\n",
    "\n",
    "        for q in question_cols:\n",
    "            my_ans = row[q]\n",
    "            if pd.isna(my_ans):\n",
    "                d[f\"{q}__mode_match\"] = np.nan\n",
    "                continue\n",
    "\n",
    "            # neighbor answers for this question\n",
    "            valid_nb = nb_df[q].dropna()\n",
    "            if valid_nb.empty:\n",
    "                d[f\"{q}__mode_match\"] = np.nan\n",
    "                continue\n",
    "\n",
    "            vc = valid_nb.value_counts(dropna=False)\n",
    "            top_count = vc.iloc[0]\n",
    "            top_vals = vc[vc == top_count].index\n",
    "\n",
    "            if tie_policy == \"strict\":\n",
    "                # require a unique mode\n",
    "                if len(top_vals) == 1:\n",
    "                    mode_val = top_vals[0]\n",
    "                    match = bool(my_ans == mode_val)\n",
    "                else:\n",
    "                    match = np.nan  # tie → unknown under strict\n",
    "            else:  # lenient\n",
    "                match = bool(my_ans in set(top_vals))\n",
    "\n",
    "            d[f\"{q}__mode_match\"] = match\n",
    "            if not pd.isna(match):\n",
    "                per_q_matches.append(bool(match))\n",
    "\n",
    "        d[\"overall_mode_match_mean\"] = np.mean(per_q_matches) if per_q_matches else np.nan\n",
    "        out_rows.append(d)\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "for year in ['20', '22', '24']:\n",
    "    jsonl_file = f\"/home/ruomeng/gae/dataset/ces/raw/{year}/neighbors_top30_semantic_{year}.jsonl\"  \n",
    "    neighbors_info = load_jsonl_as_dict_of_dict(jsonl_file, key='caseid')\n",
    "    caseid_lst = list(neighbors_info.keys())\n",
    "    print('len(caseid_lst)', len(caseid_lst))\n",
    "    # print(neighbors_info['1249937987'])\n",
    "    df_survey = pd.read_csv(f\"/home/ruomeng/gae/dataset/ces/raw/{year}/question_{year}.csv\")\n",
    "\n",
    "    # Example usage:\n",
    "    for top_k in [30]:\n",
    "        sim_df = neighbor_mode_match(df_survey, neighbors_info, id_col=\"caseid\", top_k=top_k)\n",
    "        avg_rate = sim_df[\"overall_mode_match_mean\"].mean(skipna=True)\n",
    "        print('Year=%s - TopK=%s '%(year, top_k), \"Average overall_mode_match_mean:\", avg_rate)\n",
    "        sim_df.to_csv('./analysis/analysis_neighbor_top%s_%s_mode.csv'%(top_k, year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bcf5e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(caseid_lst) 6175\n",
      "Year=20 - TopK=30  Average overall_wmode_match_mean: 0.6938491772532912\n",
      "len(caseid_lst) 6175\n",
      "Year=22 - TopK=30  Average overall_wmode_match_mean: 0.6903654228410767\n",
      "len(caseid_lst) 6175\n",
      "Year=24 - TopK=30  Average overall_wmode_match_mean: 0.6959471042340476\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "def neighbor_weighted_mode_match(\n",
    "    df_survey: pd.DataFrame,\n",
    "    neighbors_info: Dict[str, Union[List[str], Dict]],\n",
    "    *,\n",
    "    id_col: str = \"caseid\",\n",
    "    question_cols: Optional[List[str]] = None,\n",
    "    top_k: Optional[int] = None,\n",
    "    tie_policy: str = \"strict\",       # \"strict\" | \"lenient\"\n",
    "    # ---- weighting options ----\n",
    "    weight_scheme: str = \"exp\",       # \"exp\" | \"linear\" | \"harmonic\"\n",
    "    gamma: float = 0.85,              # for exp: w_i ∝ gamma^(i)\n",
    "    alpha: float = 1.0,               # for harmonic: w_i ∝ 1/(i+1)^alpha\n",
    "    normalize_weights: bool = True,\n",
    "    col_suffix: str = \"wmode\",        # output col suffix: <q>__wmode_match\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    对每个受访者和题目，比较“自己的答案”与“按邻居顺序加权后的邻居众数(Weighted Mode)”是否一致。\n",
    "    邻居列表有序：靠前的邻居权重更大（指数/线性/调和三种可选）。\n",
    "\n",
    "    输出：\n",
    "      - 每题一个布尔/NaN列：<q>__{col_suffix}_match\n",
    "      - overall_{col_suffix}_match_mean：各题(忽略NaN)的平均匹配率\n",
    "\n",
    "    tie_policy:\n",
    "      - \"strict\": 需要唯一的加权众数；若并列最大 → NaN\n",
    "      - \"lenient\": 若自答在并列最大集合里 → 记为匹配\n",
    "    \"\"\"\n",
    "    if id_col not in df_survey.columns:\n",
    "        raise ValueError(f\"`{id_col}` not found in survey data.\")\n",
    "    if question_cols is None:\n",
    "        question_cols = [c for c in df_survey.columns if c != id_col]\n",
    "    if tie_policy not in (\"strict\", \"lenient\"):\n",
    "        raise ValueError(\"tie_policy must be 'strict' or 'lenient'\")\n",
    "    if weight_scheme not in (\"exp\", \"linear\", \"harmonic\"):\n",
    "        raise ValueError(\"weight_scheme must be 'exp' | 'linear' | 'harmonic'\")\n",
    "\n",
    "    # --- clean survey data ---\n",
    "    df = df_survey.copy()\n",
    "    df = df.replace(-1, np.nan)   # 习惯上把 -1 当缺失\n",
    "    df[id_col] = df[id_col].astype(str)\n",
    "\n",
    "    # id -> row index\n",
    "    id_to_idx = pd.Series(df.index.values, index=df[id_col]).to_dict()\n",
    "\n",
    "    def _rank_weights(n: int) -> np.ndarray:\n",
    "        if n <= 0:\n",
    "            return np.array([], dtype=float)\n",
    "        if weight_scheme == \"exp\":\n",
    "            w = np.array([gamma**i for i in range(n)], dtype=float)   # i: 0..n-1\n",
    "        elif weight_scheme == \"linear\":\n",
    "            w = np.arange(n, 0, -1, dtype=float)                      # n, n-1, ..., 1\n",
    "        else:  # harmonic\n",
    "            w = 1.0 / (np.arange(n, dtype=float) + 1.0)**alpha\n",
    "        if normalize_weights and w.sum() > 0:\n",
    "            w = w / w.sum()\n",
    "        return w\n",
    "\n",
    "    out_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        cid = row[id_col]\n",
    "        neighbors = neighbors_info.get(cid, [])\n",
    "        if isinstance(neighbors, dict) and \"neighbors\" in neighbors:\n",
    "            neighbors = neighbors[\"neighbors\"]\n",
    "\n",
    "        # 归一化 id，并保持原顺序（按相似度从高到低的假设）\n",
    "        neighbors = [str(n) for n in neighbors if str(n) in id_to_idx and str(n) != cid]\n",
    "        if top_k:\n",
    "            neighbors = neighbors[:top_k]\n",
    "\n",
    "        d = {id_col: cid}\n",
    "        per_q_matches = []\n",
    "\n",
    "        if not neighbors:\n",
    "            for q in question_cols:\n",
    "                d[f\"{q}__{col_suffix}_match\"] = np.nan\n",
    "            d[f\"overall_{col_suffix}_match_mean\"] = np.nan\n",
    "            out_rows.append(d)\n",
    "            continue\n",
    "\n",
    "        nb_idx = [id_to_idx[n] for n in neighbors]\n",
    "        nb_df = df.loc[nb_idx, question_cols]         # 行顺序与 neighbors 一致\n",
    "        weights = _rank_weights(len(nb_idx))          # 与行顺序对齐\n",
    "\n",
    "        for q in question_cols:\n",
    "            my_ans = row[q]\n",
    "            if pd.isna(my_ans):\n",
    "                d[f\"{q}__{col_suffix}_match\"] = np.nan\n",
    "                continue\n",
    "\n",
    "            # 逐邻居累加加权计数（按顺序）\n",
    "            counts = defaultdict(float)\n",
    "            col_vals = nb_df[q].values  # ndarray 与 weights 同长度、同顺序\n",
    "            for i, a in enumerate(col_vals):\n",
    "                if pd.notna(a):\n",
    "                    counts[a] += weights[i]\n",
    "\n",
    "            if not counts:\n",
    "                d[f\"{q}__{col_suffix}_match\"] = np.nan\n",
    "                continue\n",
    "\n",
    "            # 选加权众数（可能并列）\n",
    "            max_w = max(counts.values())\n",
    "            top_vals = [ans for ans, w in counts.items() if np.isclose(w, max_w)]\n",
    "\n",
    "            if tie_policy == \"strict\":\n",
    "                if len(top_vals) == 1:\n",
    "                    match = bool(my_ans == top_vals[0])\n",
    "                else:\n",
    "                    match = np.nan\n",
    "            else:  # lenient\n",
    "                match = bool(my_ans in set(top_vals))\n",
    "\n",
    "            d[f\"{q}__{col_suffix}_match\"] = match\n",
    "            if not pd.isna(match):\n",
    "                per_q_matches.append(bool(match))\n",
    "\n",
    "        d[f\"overall_{col_suffix}_match_mean\"] = np.mean(per_q_matches) if per_q_matches else np.nan\n",
    "        out_rows.append(d)\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "\n",
    "for year in ['20', '22', '24']:\n",
    "    jsonl_file = f\"/home/ruomeng/gae/dataset/ces/raw/{year}/neighbors_top30_semantic_{year}.jsonl\"  \n",
    "    neighbors_info = load_jsonl_as_dict_of_dict(jsonl_file, key='caseid')\n",
    "    caseid_lst = list(neighbors_info.keys())\n",
    "    print('len(caseid_lst)', len(caseid_lst))\n",
    "    # print(neighbors_info['1249937987'])\n",
    "    df_survey = pd.read_csv(f\"/home/ruomeng/gae/dataset/ces/raw/{year}/question_{year}.csv\")\n",
    "\n",
    "    # Example usage:\n",
    "    for top_k in [30]:\n",
    "        sim_df = neighbor_weighted_mode_match(df_survey, neighbors_info, id_col=\"caseid\", top_k=top_k)\n",
    "        avg_rate = sim_df[\"overall_wmode_match_mean\"].mean(skipna=True)\n",
    "        print('Year=%s - TopK=%s '%(year, top_k), \"Average overall_wmode_match_mean:\", avg_rate)\n",
    "        sim_df.to_csv('./analysis/analysis_neighbor_top%s_%s_wmode.csv'%(top_k, year))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
